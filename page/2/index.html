<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="start from zero">
<meta property="og:type" content="website">
<meta property="og:title" content="thinks&#39;s blog">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="thinks&#39;s blog">
<meta property="og:description" content="start from zero">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="thinks&#39;s blog">
<meta name="twitter:description" content="start from zero">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/">





  <title>thinks's blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
    <a href="https://github.com/liken95"><img width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_darkblue_121621.png?resize=149%2C149" class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">thinks's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/31/数组求和/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/31/数组求和/" itemprop="url">数组求和问题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-31T19:51:34+08:00">
                2019-03-31
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/leetcode/" itemprop="url" rel="index">
                    <span itemprop="name">leetcode</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  580
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-001-two-sum"><a href="#1-001-two-sum" class="headerlink" title="1. 001 two sum"></a>1. 001 two sum</h2><p>Given an array of integers, return indices of the two numbers such that they add up to a specific target.</p>
<p>You may assume that each input would have exactly one solution, and you may not use the same element twice.</p>
<p>Example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Given nums = [2, 7, 11, 15], target = 9,</span><br><span class="line"></span><br><span class="line">Because nums[0] + nums[1] = 2 + 7 = 9,</span><br><span class="line">return [0, 1].</span><br></pre></td></tr></table></figure>
<p>solution:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution(object):</span><br><span class="line">    def twoSum(self, nums, target):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :type nums: List[int]</span><br><span class="line">        :type target: int</span><br><span class="line">        :rtype: List[int]≥</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        dic = dict&#123;&#125;</span><br><span class="line">        for i in range(len(nums)):</span><br><span class="line">            j = target - num[i]</span><br><span class="line">            if j in nums:</span><br><span class="line">                return [i,target-num[i]]</span><br><span class="line">            else:</span><br><span class="line">                return</span><br></pre></td></tr></table></figure>
<h2 id="2-015-three-sum"><a href="#2-015-three-sum" class="headerlink" title="2. 015 three sum"></a>2. 015 three sum</h2><p>给定一个包含n个整数的数组nums,判断nums中是否存在三个元素a,b,c，使得a+b+c=0？找出所有满足条件且不重复的三元组。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">例如，给定数组nums = [-1,0,1,2,-1,-4]，满足要求的三元组集合为</span><br><span class="line">[</span><br><span class="line">    [-1,0,1],</span><br><span class="line">    [-1,-1,2]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>思路：</p>
<p>3Sum其实可以转化成一个2Sum的题，我们先从数组中选一个数，并将目标数减去这个数，得到一个新目标数。然后再在剩下的数中找一对和是这个新目标数的数，其实就转化为2Sum了。为了避免得到重复结果，我们不仅要跳过重复元素，而且要保证2Sum找的范围要是在我们最先选定的那个数之后的。</p>
<p>solution:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">nums.sort()</span><br><span class="line">res = set()</span><br><span class="line"></span><br><span class="line">for i, v_i in enumerate(nums[:-2]): # 新</span><br><span class="line"></span><br><span class="line">    if i &gt;= 1 and v_i == nums[i - 1]:</span><br><span class="line">        continue</span><br><span class="line"></span><br><span class="line">    seen_set = set()# 新</span><br><span class="line">    for num in nums[i + 1:]:</span><br><span class="line"></span><br><span class="line">        search = 0 - (v_i + num)</span><br><span class="line">        if search in seen_set:</span><br><span class="line">            res.add((v_i, search, num))</span><br><span class="line">        else:</span><br><span class="line">            seen_set.add(num)</span><br><span class="line"></span><br><span class="line">return list(res)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-018-四数之和"><a href="#3-018-四数之和" class="headerlink" title="3. 018 四数之和"></a>3. 018 四数之和</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给定一个包含 n个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素a，b，c 和d ，使得 a+b+c+d 的值与 target 相等？找出所有满足条件且不重复的四元组。</span><br></pre></td></tr></table></figure>
<p>example：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">给定数组 nums = [1, 0, -1, 0, -2, 2]，和 target = 0。</span><br><span class="line"></span><br><span class="line">满足要求的四元组集合为：</span><br><span class="line">[</span><br><span class="line">[-1, 0, 0, 1],</span><br><span class="line">[-2, -1, 1, 2],</span><br><span class="line">[-2, 0, 0, 2]</span><br></pre></td></tr></table></figure>
<p>solution:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">nums.sort()</span><br><span class="line">len_nums = len(nums)</span><br><span class="line">res = set()</span><br><span class="line"></span><br><span class="line"># 外层由遍历一轮变成遍历两轮</span><br><span class="line">for i in range(len_nums - 3): # 新</span><br><span class="line"></span><br><span class="line">    if i &gt;= 1 and nums[i] == nums[i-1]:</span><br><span class="line">        continue</span><br><span class="line"></span><br><span class="line">    for j in range(i+1, len_nums - 2):</span><br><span class="line"></span><br><span class="line">        if j &gt;= i + 2 and nums[j] == nums[j-1]:</span><br><span class="line">            continue</span><br><span class="line"></span><br><span class="line">        seen_set = set()</span><br><span class="line"></span><br><span class="line">        # 一样的双数的HashSet</span><br><span class="line">        for v_k in nums[j+1:]:</span><br><span class="line">            search = target - nums[i] - nums[j] - v_k</span><br><span class="line"></span><br><span class="line">            if search in seen_set:</span><br><span class="line">                res.add((nums[i], nums[j], search, v_k))</span><br><span class="line">            else:</span><br><span class="line">                seen_set.add(v_k)</span><br><span class="line"></span><br><span class="line">return list(res)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/27/正则表达式-1/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/27/正则表达式-1/" itemprop="url">正则表达式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-27T17:15:59+08:00">
                2019-03-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  0
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/04/xgt算法梳理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/04/xgt算法梳理/" itemprop="url">xgb算法梳理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-04T16:32:18+08:00">
                2019-03-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-算法/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习 算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一、CART树"><a href="#一、CART树" class="headerlink" title="一、CART树"></a>一、CART树</h2><p>决策树时机器学习中古老的算法，可以看做是一组嵌套的判定规则，这组规则通过训练得到。从数学上看，决策树是一个分段常数函数，每个叶子节点对应空间中的一片区域，落入此区域的向量x被预测为该叶子节点的值。</p>
<p>分类与回归树是二叉决策树的一种，既可以用于分类问题，也可以用于回归问题。训练时要解决的核心问题是寻找最佳分裂来确定内部节点，递归构建树，为叶子节点赋予标签值。对于分类问题，寻找最佳分裂时的目标是最大化Gini纯度值，简化后的计算公式为</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g0qutawi0uj30ec04aq31.jpg" alt=""></p>
<p>其中NL是分裂之后左子节点的训练样本数，NL,i是左子节点中第i类样本数；NR是分裂之后右子节点的训练样本数，NR,i是右子节点中第i类样本数。对于回归问题，寻找最佳分裂时优化的目标是最大化回归误差的下降值</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0qutkt538j30pq03adg6.jpg" alt=""></p>
<p>因为特征向量中有多个特征，因此实现时需要为每个特征分量计算最佳分裂阈值，然后取其中最优的。为单个特征计算最佳分裂阈值时，首先将该节点的所有训练样本按照该特征分量从小到大排序，然后依次以每个特征值作为阈值，将样本集分为左右两个子集，然后计算上面的分裂指标，取其最优值。具体原理在《机器学习与应用》一书中已经详细讲述。</p>
<p>第二个问题是叶子节点值的设定。对于分类问题，将叶子节点的值设置成本节点的训练样本集中出现概率最大的那个类；对于回归树，则设置为本节点训练样本标签值的均值。 </p>
<h2 id="二、算法原理"><a href="#二、算法原理" class="headerlink" title="二、算法原理"></a>二、算法原理</h2><ol>
<li><p>初始化 f_0(x) </p>
</li>
<li><p>for m=1 to M :</p>
</li>
</ol>
<p>(a) 计算损失函数在每个训练样本点的一阶导数和二阶导数 </p>
<p>(b) 递归地运用树分裂算法生成一颗决策树</p>
<p>(c) 把新生成的决策树添加到模型中</p>
<h2 id="三、损失函数"><a href="#三、损失函数" class="headerlink" title="三、损失函数"></a>三、损失函数</h2><p>XGBoost的损失函数定义为</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0quu5g5nqj30qe04kwet.jpg" alt=""></p>
<p>其中n为训练样本数，l是对单个样本的损失，yi’为预测值,yi为样本真实标签值，Φ为模型的参数。正则化项定义了模型的复杂程度</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0quufr1atj30j4048q33.jpg" alt=""></p>
<p>其中γ和λ为人工设置的系数，w为决策树所有叶子节点值形成的向量，T为叶子节点数。正则化项由叶子节点数，叶子节点值向量的模平方两项构成，第一项体现了决策树结构的复杂程度，第二项体现了决策树预测值的复杂程度。定义q为输入向量X到决策树叶子节点编号的映射，即根据输入向量确定用决策树的第几个叶子节点值来预测它的输出值</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g0quuvuvbdj30fe02ydfw.jpg" alt=""></p>
<p>其中d为特征向量的维数。因此q定义了树的结构，w定义了树的输出值。决策树的映射函数可以写成</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g0quvaczloj30b0036dfu.jpg" alt=""></p>
<p>与梯度提升算法相同，采用加法模型表示强学习器。假设yi,t’为第i个样本在第t次迭代时的强学习器预测值，训练时依次确定每一个弱学习器函数ft，加到强学习器预测函数中，即最小化如下目标函数</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0quy0ahkvj30qi04kt91.jpg" alt=""></p>
<p>实现时用贪婪法将ft加入到模型中，以最小化目标函数值。注意，在这里yi是常数，yi,t-1’+f(xi）是损失函数的自变量，而yi,t-1’也是常数。对于一般的损失函数无法求得上面优化问题的公式解。采用牛顿法近似求解，对目标函数在yi,t-1’点处作二阶泰勒展开后得到</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0quyff3axj30u003it94.jpg" alt=""></p>
<p>损失函数的一阶导数为</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0quyqzf0wj30ik05egls.jpg" alt=""></p>
<p>与梯度提升算法相同，是将之前已经训练得到的强学习器对样本的预测值当做变量求导，这一点一定要理解，很多读者困惑的地方在于不知道这个导数是对谁求导。损失函数的二阶导数为</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0quz11e12j30ia05maa8.jpg" alt=""></p>
<h2 id="四、分裂结点算法"><a href="#四、分裂结点算法" class="headerlink" title="四、分裂结点算法"></a>四、分裂结点算法</h2><p>1、暴力枚举</p>
<p>2、近似方法 ，近似方法通过特征的分布，按照百分比确定一组候选分裂点，通过遍历所有的候选分裂点来找到最佳分裂点。<br>两种策略：全局策略和局部策略。在全局策略中，对每一个特征确定一个全局的候选分裂点集合，就不再改变；而在局部策略中，每一次分裂 都要重选一次分裂点。前者需要较大的分裂集合，后者可以小一点。对比补充候选集策略与分裂点数目对模型的影响。 全局策略需要更细的分裂点才能和局部策略差不多</p>
<p>3、Weighted Quantile Sketch</p>
<h2 id="五、正则化"><a href="#五、正则化" class="headerlink" title="五、正则化"></a>五、正则化</h2><p>1）像Adaboost和GBDT中一样，对每一个模型乘以一个系数λ（0 &lt; λ ≤ 1），用来降低每个模型对结果的贡献<br>2）采用特征子采样方法，和RandomForest中的特征子采样一样，可以降低模型的方差</p>
<h2 id="六、对缺失值处理"><a href="#六、对缺失值处理" class="headerlink" title="六、对缺失值处理"></a>六、对缺失值处理</h2><p>xgboost处理缺失值的方法和其他树模型不同。xgboost把缺失值当做稀疏矩阵来对待，本身的在节点分裂时不考虑的缺失值的数值。缺失值数据会被分到左子树和右子树分别计层损失，选择较优的那一个。如果训练中没有数据缺失，预测时出现了数据缺失，那么默认被分类到右子树。</p>
<p><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0qylmcbqpj30cs0dc0y4.jpg" alt=""></p>
<p>这样的处理方法固然巧妙，但也有风险：假设了训练数据和预测数据的分布相同，比如缺失值的分布也相同，不过直觉上应该影响不是很大。</p>
<h2 id="七、优缺点"><a href="#七、优缺点" class="headerlink" title="七、优缺点"></a>七、优缺点</h2><p>与GBDT相比，xgBoosting有以下进步：</p>
<p>1）GBDT以传统CART作为基分类器，而xgBoosting支持线性分类器，相当于引入L1和L2正则化项的逻辑回归（分类问题）和线性回归（回归问题）；</p>
<p>2）GBDT在优化时只用到一阶导数，xgBoosting对代价函数做了二阶Talor展开，引入了一阶导数和二阶导数；</p>
<p>3）当样本存在缺失值是，xgBoosting能自动学习分裂方向；</p>
<p>4）xgBoosting借鉴RF的做法，支持列抽样，这样不仅能防止过拟合，还能降低计算；</p>
<p>5）xgBoosting的代价函数引入正则化项，控制了模型的复杂度，正则化项包含全部叶子节点的个数，每个叶子节点输出的score的L2模的平方和。从贝叶斯方差角度考虑，正则项降低了模型的方差，防止模型过拟合；</p>
<p>6）xgBoosting在每次迭代之后，为叶子结点分配学习速率，降低每棵树的权重，减少每棵树的影响，为后面提供更好的学习空间；</p>
<p>7）xgBoosting工具支持并行,但并不是tree粒度上的，而是特征粒度，决策树最耗时的步骤是对特征的值排序，xgBoosting在迭代之前，先进行预排序，存为block结构，每次迭代，重复使用该结构，降低了模型的计算；block结构也为模型提供了并行可能，在进行结点的分裂时，计算每个特征的增益，选增益最大的特征进行下一步分裂，那么各个特征的增益可以开多线程进行；<br>8）可并行的近似直方图算法，树结点在进行分裂时，需要计算每个节点的增益，若数据量较大，对所有节点的特征进行排序，遍历的得到最优分割点，这种贪心法异常耗时，这时引进近似直方图算法，用于生成高效的分割点，即用分裂后的某种值减去分裂前的某种值，获得增益，为了限制树的增长，引入阈值，当增益大于阈值时，进行分裂；</p>
<p>然而，与LightGBM相比，又表现出了明显的不足：</p>
<p>1）xgBoosting采用预排序，在迭代之前，对结点的特征做预排序，遍历选择最优分割点，数据量大时，贪心法耗时，LightGBM方法采用histogram算法，占用的内存低，数据分割的复杂度更低；</p>
<p>2）xgBoosting采用level-wise生成决策树，同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合，但很多叶子节点的分裂增益较低，没必要进行跟进一步的分裂，这就带来了不必要的开销；LightGBM采用深度优化，leaf-wise生长策略，每次从当前叶子中选择增益最大的结点进行分裂，循环迭代，但会生长出更深的决策树，产生过拟合，因此引入了一个阈值进行限制，防止过拟合.</p>
<h2 id="八、应用场景"><a href="#八、应用场景" class="headerlink" title="八、应用场景"></a>八、应用场景</h2><p>跟决策树一样，多应用于分类问题</p>
<p>行业应用、业务优化</p>
<h2 id="九、sklearn参数"><a href="#九、sklearn参数" class="headerlink" title="九、sklearn参数"></a>九、sklearn参数</h2><p>General Parameters（常规参数） </p>
<p>1.booster [default=gbtree]：选择基分类器，gbtree: tree-based models/gblinear: linear models </p>
<p>2.silent [default=0]:设置成1则没有运行信息输出，最好是设置为0. </p>
<p>3.nthread [default to maximum number of threads available if not set]：线程数</p>
<p>Booster Parameters（模型参数） </p>
<p>1.eta [default=0.3]:shrinkage参数，用于更新叶子节点权重时，乘以该系数，避免步长过大。参数值越大，越可能无法收敛。把学习率 eta 设置的小一些，小学习率可以使得后面的学习更加仔细。 </p>
<p>2.min_child_weight [default=1]:这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 </p>
<p>3.max_depth [default=6]: 每颗树的最大深度，树高越深，越容易过拟合。 </p>
<p>4.max_leaf_nodes:最大叶结点数，与max_depth作用有点重合。 </p>
<p>5.gamma [default=0]：后剪枝时，用于控制是否后剪枝的参数。 </p>
<p>6.max_delta_step [default=0]：这个参数在更新步骤中起作用，如果取0表示没有约束，如果取正值则使得更新步骤更加保守。可以防止做太大的更新步子，使更新更加平缓。 </p>
<p>7.subsample [default=1]：样本随机采样，较低的值使得算法更加保守，防止过拟合，但是太小的值也会造成欠拟合。 </p>
<p>8.colsample_bytree [default=1]：列采样，对每棵树的生成用的特征进行列采样.一般设置为： 0.5-1 </p>
<p>9.lambda [default=1]：控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。 </p>
<p>10.alpha [default=0]:控制模型复杂程度的权重值的 L1 正则项参数，参数值越大，模型越不容易过拟合。 </p>
<p>11.scale_pos_weight [default=1]：如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。</p>
<p>Learning Task Parameters（学习任务参数） </p>
<p>1.objective [default=reg:linear]：定义最小化损失函数类型，常用参数： </p>
<p>binary:logistic –logistic regression for binary classification, returns predicted probability (not class) </p>
<p>multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities) </p>
<p>you also need to set an additional num_class (number of classes) parameter defining the number of unique classes </p>
<p>multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class. </p>
<p>2.eval_metric [ default according to objective ]：<br>The metric to be used for validation data.<br>The default values are rmse for regression and error for classification. </p>
<p>Typical values are: </p>
<p>rmse – root mean square error<br>mae – mean absolute error<br>logloss – negative log-likelihood<br>error – Binary classification error rate (0.5 threshold)<br>merror – Multiclass classification error rate<br>mlogloss – Multiclass logloss<br>auc: Area under the curve </p>
<p>3.seed [default=0]： </p>
<p>The random number seed. 随机种子，用于产生可复现的结果<br>Can be used for generating reproducible results and also for parameter tuning.</p>
<p>注意: python sklearn style参数名会有所变化<br>eta –&gt; learning_rate<br>lambda –&gt; reg_lambda </p>
<h2 id="alpha-–-gt-reg-alpha"><a href="#alpha-–-gt-reg-alpha" class="headerlink" title="alpha –&gt; reg_alpha"></a>alpha –&gt; reg_alpha</h2><p>作者：我曾经被山河大海跨过 </p>
<p>来源：CSDN </p>
<p>原文：<a href="https://blog.csdn.net/sb19931201/article/details/52557382" target="_blank" rel="noopener">https://blog.csdn.net/sb19931201/article/details/52557382</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>

          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/02/GBDT算法梳理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/02/GBDT算法梳理/" itemprop="url">GBDT算法梳理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-02T16:08:20+08:00">
                2019-03-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  3.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  13
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>GBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。  </p>
<h3 id="前向分布算法"><a href="#前向分布算法" class="headerlink" title="前向分布算法"></a>前向分布算法</h3><p>Adaboost算法的模型可认为是加法模型，加法模型的优化通常是一个复杂的优化问题，前向分布算法求解这一优化问题的思路是：<strong>从前往后每一步只学习一个基函数及其系数，逐步逼近优化目标函数。</strong><br><img src="https://upload-images.jianshu.io/upload_images/1667471-10debca340107bc0.png" alt="1"><br>这样，前向分布算法将同时求解从m=1到M的所有参数βm, rm的优化问题简化为逐次求解各个βm, rm的优化问题</p>
<h3 id="负梯度拟合"><a href="#负梯度拟合" class="headerlink" title="负梯度拟合"></a>负梯度拟合</h3><p>为了解决损失函数拟合方法的问题，Freidman提出了用损失函数的负梯度来拟合本轮损失的近似值，进而拟合一个CART回归树。第t轮的第i个样本的损失函数的负梯度表示为<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0ppjs3vjij30bc02jgli.jpg" alt="2"></p>
<p>利用(xi,rti)(i=1,2,..m),我们可以拟合一颗CART回归树，得到了第t颗回归树，其对应的叶节点区域Rtj,j=1,2,…,J。其中J为叶子节点的个数。<br>针对每一个叶子节点里的样本，我们求出使损失函数最小，也就是拟合叶子节点最好的的输出值ctj如下：<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0ppm9yyqej30c8036jrb.jpg" alt="7"><br>这样我们就得到了本轮的决策树拟合函数如下：<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0ppne2d7gj308z02ot8k.jpg" alt="8"><br>从而本轮最终得到的强学习器的表达式如下：<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0ppo3ktk8j30am01z3yd.jpg" alt="9"><br>通过损失函数的负梯度来拟合，我们找到了一种通用的拟合损失误差的办法，这样无轮是分类问题还是回归问题，我们通过其损失函数的负梯度的拟合，就可以用GBDT来解决我们的分类回归问题。区别仅仅在于损失函数不同导致的负梯度不同而已。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>对于分类算法，其损失函数一般有对数损失函数和指数损失函数两种:<br>a) 如果是指数损失函数，则损失函数表达式为     </p>
<p>L(y,f(x))=exp(−yf(x))  </p>
<p>b) 如果是对数损失函数，分为二元分类和多元分类两种。<br>  对于回归算法，常用损失函数有如下4种:<br>a)均方差，这个是最常见的回归损失函数<br>L(y,f(x))=(y−f(x))^2<br>b)绝对损失，这个损失函数也很常见<br>L(y,f(x))=|y−f(x)|<br>对应负梯度误差为：<br>sign(yi−f(xi))<br>c)Huber损失，它是均方差和绝对损失的折衷产物，对于远离中心的异常点，采用绝对损失，而中心附近的点采用均方差。这个界限一般用分位数点度量。损失函数如下：<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pqxxyebmj30ep026wei.jpg" alt="15">   </p>
<p>对应的负梯度误差为：<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pqyuqwfpj30fe031mx5.jpg" alt="16"><br>d) 分位数损失。它对应的是分位数回归的损失函数，表达式为<br> <img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0prdm1kl3j30g902lmx3.jpg" alt="17"><br> 其中θ为分位数，需要我们在回归前指定。对应的负梯度误差为：<br> <img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pretko4mj30a002e0sl.jpg" alt="18"><br> 对于Huber损失和分位数损失，主要用于健壮回归，也就是减少异常点对损失函数的影响。</p>
<h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><p>　输入是训练集样本,T={(x,y1),(x2,y2),…(xm,ym)},最大迭代次数T, 损失函数L。输出是强学习器f(x)<br> 初始化弱学习器<br> <img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0ppsadsjfj30at048gli.jpg" alt="8"><br> 对迭代轮数t=1,2,…T有：<br>a)对样本i=1,2，…m，计算负梯度<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0ppwft9vij30bc02f0sn.jpg" alt="9"><br>b)利用(xi,rti)(i=1,2,..m), 拟合一颗CART回归树,得到第t颗回归树，其对应的叶子节点区域为Rtj,j=1,2,…,J。其中J为回归树t的叶子节点的个数。<br>c) 对叶子区域j =1,2,..J,计算最佳拟合值<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pqn6f56tj30d102ljra.jpg" alt="10"><br>d) 更新强学习器<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pqnxqy4rj30c803n746.jpg" alt="11"><br>得到强学习器f(x)的表达式<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pqocmpmbj30e102sa9z.jpg" alt="12"></p>
<h3 id="二分类，多分类"><a href="#二分类，多分类" class="headerlink" title="二分类，多分类"></a>二分类，多分类</h3><p>GBDT的分类算法从思想上和GBDT的回归算法没有区别，但是由于样本输出不是连续的值，而是离散的类别，导致我们无法直接从输出类别去拟合类别输出的误差。<br>为了解决这个问题，主要有两个方法，一个是用指数损失函数，此时GBDT退化为Adaboost算法。另一种方法是用类似于逻辑回归的对数似然损失函数的方法。也就是说，我们用的是类别的预测概率值和真实概率值的差来拟合损失。本文仅讨论用对数似然损失函数的GBDT分类。而对于对数似然损失函数，我们又有二元分类和多元分类的区别。<br><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pqtxirz1j30o00git9z.jpg" alt="13"></p>
<p><img src="http://ww1.sinaimg.cn/large/005tJ8mQly1g0pqv8lz5wj30ss0ocmz6.jpg" alt="14"><br>除了负梯度计算和叶子节点的最佳负梯度拟合的线性搜索，多元GBDT分类和二元GBDT分类以及GBDT回归算法过程相同。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>针对GBDT正则化，我们通过子采样比例方法和定义步长v方法来防止过拟合。</p>
<p><strong>子采样比例:</strong> 通过不放回抽样的子采样比例（subsample），取值为(0,1]。如果取值为1，则全部样本都使用。如果取值小于1，利用部分样本去做GBDT的决策树拟合。选择小于1的比例可以减少方差，防止过拟合，但是会增加样本拟合的偏差。因此取值不能太低，推荐在[0.5, 0.8]之间。</p>
<p><strong>定义步长v:</strong> 针对弱学习器的迭代，我们定义步长v，取值为(0,1]。对于同样的训练集学习效果，较小的v意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点：  </p>
<ol>
<li>相对少的调参时间情况下可以得到较高的准确率。  </li>
<li>可灵活处理各种类型数据，包括连续值和离散值，使用范围广。  </li>
<li>可使用一些健壮的损失函数，对异常值的鲁棒性较强，比如Huber损失函数。    </li>
</ol>
<p>缺点  </p>
<ol>
<li>弱学习器之间存在依赖关系，难以并行训练数据</li>
</ol>
<h3 id="sklearn参数"><a href="#sklearn参数" class="headerlink" title="sklearn参数"></a>sklearn参数</h3><p><strong>sklearn GBDT类库概述</strong></p>
<p>在sklearn中，Gradient Boosting Classifier为GBDT的分类类， 而Gradient Boosting Regressor为GBDT的回归类。两者的参数类型完全相同，当然有些参数比如损失函数loss的可选择项并不相同。这些参数中，类似于Adaboost，我们把重要参数分为两类，第一类是Boosting框架的重要参数，第二类是弱学习器即CART回归树的重要参数。</p>
<p><strong>GBDT类库boosting框架参数</strong></p>
<p>首先，我们来看boosting框架相关的重要参数。由于Gradient Boosting Classifier和Gradient Boosting Regressor的参数绝大部分相同，我们下面会一起来讲，不同点会单独指出。</p>
<p>1, n_estimators: 也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，一般选择一个适中的数值。默认是100。在实际调参的过程中，我们常常将n_estimators和下面介绍的参数learning_rate一起考虑。</p>
<p>2, learning_rate: 即每个弱学习器的权重缩减系数<br>ν，也称作步长，在原理篇的正则化章节我们也讲到了，加上了正则化项，我们的强学习器的迭代公式为<br>fk(x)=fk−1(x)+νhk(x), ν的取值范围为0&lt;ν≤1.对于同样的训练集拟合效果，较小的<br>ν意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。所以这两个参数n_estimators和learning_rate要一起调参。一般来说，可以从一个小一点的ν开始调参，默认是1。</p>
<p>3, subsample: 即我们在原理篇的正则化章节讲到的子采样，取值为(0,1]。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5, 0.8]之间，默认是1.0，即不使用子采样。</p>
<p>4, init: 即我们的初始化的时候的弱学习器，如果不输入，则用训练集样本来做样本集的初始化分类回归预测。否则用init参数提供的学习器做初始化分类回归预测。一般用在我们对数据有先验知识，或者之前做过一些拟合的时候，如果没有的话就不用管这个参数了。</p>
<p>5, loss: 即我们GBDT算法中的损失函数。分类模型和回归模型的损失函数是不一样的。</p>
<blockquote>
<p>对于分类模型，有对数似然损失函数”deviance”和指数损失函数”exponential”两者输入选择。默认是对数似然损失函数”deviance”。在原理篇中对这些分类损失函数有详细的介绍。一般来说，推荐使用默认的”deviance”。它对二元分离和多元分类各自都有比较好的优化。而指数损失函数等于把我们带到了Adaboost算法。</p>
</blockquote>
<blockquote>
<p>对于回归模型，有均方差”ls”, 绝对损失”lad”, Huber损失”huber”和分位数损失“quantile”。默认是均方差”ls”。一般来说，如果数据的噪音点不多，用默认的均方差”ls”比较好。如果是噪音点较多，则推荐用抗噪音的损失函数”huber”。而如果我们需要对训练集进行分段预测的时候，则采用“quantile”。</p>
</blockquote>
<p>6, alpha：这个参数只有Gradient  Boosting Regressor有，当我们使用Huber损失”huber”和分位数损失“quantile”时，需要指定分位数的值。默认是0.9，如果噪音点较多，可以适当降低这个分位数的值。<br><strong>GBDT类库弱学习器参数</strong></p>
<p>这里我们再对GBDT的类库弱学习器的重要参数做一个总结。由于GBDT使用了CART回归决策树，因此它的参数基本来源于决策树类，也就是说，和Decision Tree Classifier和Decision Tree Regressor的参数基本类似。<br>1, max_features: RF划分时考虑的最大特征数。可以使用很多种类型的值，默认是”None”,意味着划分时考虑所有的特征数；如果是”log2”意味着划分时最多考虑log2N个特征；如果是”sqrt”或者”auto”意味着划分时最多考虑N−−√N个特征。如果是整数，代表考虑的特征绝对数。如果是浮点数，代表考虑特征百分比，即考虑（百分比xN）取整后的特征数，其中N为样本总特征数。一般来说，如果样本特征数不多，比如小于50，我们用默认的”None”就可以了，如果特征数非常多，我们可以灵活使用刚才描述的其他取值来控制划分时考虑的最大特征数，以控制决策树的生成时间。<br>2,max_depth:决策树最大深度。默认为”None”，决策树在建立子树的时候不会限制子树的深度这样建树时，会使每一个叶节点只有一个类别，或是达到min_samples_split。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。<br>3,min_samples_split:内部节点再划分所需最小样本数，默认2。这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。<br>4, min_samples_leaf:叶子节点最少样本数。这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。默认是1,可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。<br>5,min_weight_fraction_leaf：叶子节点最小的样本权重和。这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。<br>6,max_leaf_nodes:最大叶子节点数。通过限制最大叶子节点数，可以防止过拟合，默认是”None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制，具体的值可以通过交叉验证得到。<br>7,min_impurity_split:节点划分最小不纯度。这个值限制了决策树的增长，如果某节点的不纯度(基于基尼系数，均方差)小于这个阈值，则该节点不再生成子节点，即为叶子节点。一般不推荐改动默认值1e-7。<br>8,presort:是否对数据进行预分类，以加快拟合中最佳分裂点的发现。默认False，适用于大数据集。小数据集使用True,可以加快训练。是否预排序,预排序可以加速查找最佳分裂点，对于稀疏数据不管用，Bool，auto：非稀疏数据则预排序，若稀疏数据则不预排序<br>上面决策树参数中最重要的包括最大特征数max_features，最大深度max_depth，内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf。</p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）  </p>

          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/02/线性回归算法/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/02/线性回归算法/" itemprop="url">线性回归算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-02T14:24:33+08:00">
                2019-03-02
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习-算法/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习 算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  53
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="一、线性回归算法概述"><a href="#一、线性回归算法概述" class="headerlink" title="一、线性回归算法概述"></a>一、线性回归算法概述</h3><blockquote>
<p>回归就是用现有的数据预测出未来的值。</p>
</blockquote>
<h2 id="二、误差项分析"><a href="#二、误差项分析" class="headerlink" title="二、误差项分析"></a>二、误差项分析</h2><h2 id="三、似然函数求解"><a href="#三、似然函数求解" class="headerlink" title="三、似然函数求解"></a>三、似然函数求解</h2><h2 id="四、目标函数推导"><a href="#四、目标函数推导" class="headerlink" title="四、目标函数推导"></a>四、目标函数推导</h2><h2 id="五、线性回归求解"><a href="#五、线性回归求解" class="headerlink" title="五、线性回归求解"></a>五、线性回归求解</h2>
          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/27/随机森林算法梳理/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/27/随机森林算法梳理/" itemprop="url">随机森林算法梳理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-27T22:24:51+08:00">
                2019-02-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  4.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  15
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一、集成学习概念"><a href="#一、集成学习概念" class="headerlink" title="一、集成学习概念"></a>一、集成学习概念</h2><p>在日常生活中我们会遇到这样的情况：对一个决策问题，如果一个人拿不定主意，可以组织多个人来集体决策。如果要判断一个病人是否患有某种疑难疾病，可以组织一批医生来会诊。会诊的做法是让每个医生做一个判断，然后收集他们的判断结果进行投票协商，得票最多的那个判断结果作为最终的结果。这种思想在机器学习领域的应用就是集成学习算法。</p>
<p>其结构如下图所示：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g0ld53t5fnj30kp0h875d.jpg" alt=""></p>
<p>也就是说，我们需要解决两个问题：</p>
<ul>
<li><p>如何得到若干个个体学习器</p>
</li>
<li><p>应采用什么样的结合策略</p>
</li>
</ul>
<h2 id="二、-个体学习器概念"><a href="#二、-个体学习器概念" class="headerlink" title="二、 个体学习器概念"></a>二、 个体学习器概念</h2><ol>
<li>之前讲到，集成学习的一个问题就是如何得到若干个个体学习器，那么我们两种选择。</li>
</ol>
<ul>
<li><p>同类型（如全是决策树，或者全是神经网络）的个体学习器</p>
</li>
<li><p>不同类型的个体学习器。比如我们有一个分类问题，对训练集采用支持向量机个体学习器、逻辑回归个体学习器和朴素贝叶斯个体学习器来学习，再通过某种结合策略来确定最终的分类强学习器。</p>
</li>
</ul>
<ol start="2">
<li>同类型个体学习器按照个体学习器之间是否存在依赖关系可以分为两类：</li>
</ol>
<ul>
<li>个体学习器之间存在强依赖关系，一系列个体学习器基本都需要串行生成，代表算法是boosting系列算法，</li>
<li>个体学习器之间不存在强依赖关系，一系列个体学习器可以并行生成，代表算法是bagging和随机森林（Random Forest）系列算法。</li>
</ul>
<h2 id="三、-boosting、bagging"><a href="#三、-boosting、bagging" class="headerlink" title="三、 boosting、bagging"></a>三、 boosting、bagging</h2><h3 id="1-boostrap概述"><a href="#1-boostrap概述" class="headerlink" title="1.boostrap概述"></a>1.boostrap概述</h3><p><strong>boostrap是一种有放回抽样</strong>。</p>
<p>例如，如果有10个样本，Bootstrap抽样从它们中随机的抽取出10个，下面两种情况都是可能发生的:</p>
<p>1 1 1 1 1 1 1 1 1 1 </p>
<p>1 2 3 4 5 6 7 8 9 10</p>
<h3 id="2-Bagging（Bootstrap-Aggregating）概述"><a href="#2-Bagging（Bootstrap-Aggregating）概述" class="headerlink" title="2.Bagging（Bootstrap Aggregating）概述"></a>2.Bagging（Bootstrap Aggregating）概述</h3><blockquote>
<p>Bagging算法对训练样本集进行<strong>多次Bootstrap抽样</strong>，每次抽样形成的数据集训练一个弱学习器模型，得到多个独立的弱学习器（对于分类问题，称为弱分类器）。结合策略也比较简单，对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对T个弱学习器得到的回归结果进行算术平均得到最终的模型输出。</p>
</blockquote>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1g0m6i5ozhij312k0iudik.jpg" alt=""></p>
<p>训练流程为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">循环，对i = 1, ..., T</span><br><span class="line"></span><br><span class="line">    对训练样本集进行Bootstrap抽样，得到抽样后的训练样本集</span><br><span class="line"></span><br><span class="line">    用抽样得到的样本集训练一个模型hi(x)</span><br><span class="line"></span><br><span class="line">结束循环</span><br><span class="line"></span><br><span class="line">输出模型组合h1(x),...,hT(x)</span><br></pre></td></tr></table></figure></p>
<p>如果弱学习器是决策树，这种方法就是随机森林。</p>
<h3 id="3-boosting概述"><a href="#3-boosting概述" class="headerlink" title="3.boosting概述"></a>3.boosting概述</h3><blockquote>
<p>Boost的含义是增强，Boosting方法就是从弱学习算法出发，在前一个学习器的基础上反复学习，得到一系列弱分类器，然后组合弱分类器，得到一个强分类器。Boosting方法在学习过程中通过改变训练数据的<strong>权值分布</strong>，针对不同的数据分布调用弱学习算法得到一系列弱分类器。</p>
</blockquote>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1g0m6gvv32dj31380ietcg.jpg" alt=""></p>
<p>各个体学习器之间是强相关的，即下一个学习器的学习偏好受之前学习器的影响很大，因为之前的个体学习器的学习情况会通过权值来影响下一次训练样本的分布情况。这种强相关性决定了AdaBoost只能进行串行运算，而且通过AdaBoost算法的推导可以知道该算法只能用于二分类任务。 </p>
<h2 id="四、-结合策略-平均法，投票法，学习法"><a href="#四、-结合策略-平均法，投票法，学习法" class="headerlink" title="四、 结合策略(平均法，投票法，学习法)"></a>四、 结合策略(平均法，投票法，学习法)</h2><p>在上面几节里面我们主要关注于如何得到若干个个体学习器，本节来介绍结合策略。</p>
<ol>
<li>平均法</li>
</ol>
<ul>
<li>简单平均法（simple averaging） </li>
</ul>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g0m6ql3hi8j30aa04mgln.jpg" alt=""></p>
<ul>
<li>加权平均法</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g0m6rr0lt1j30cu04m0ss.jpg" alt=""></p>
<ol start="2">
<li>投票法则有三种方法：</li>
</ol>
<ul>
<li>相对多数投票法</li>
</ul>
<p>即少数服从多数</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g0m6tw2dhbj30ge050jri.jpg" alt=""></p>
<ul>
<li>绝对多数投票法</li>
</ul>
<p>在相对多数投票法的基础上，不光要求获得最高票，还要求票过半数。否则会拒绝预测。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g0m6uaceooj30si052wez.jpg" alt=""></p>
<ul>
<li>加权投票法</li>
</ul>
<p>每个弱学习器的分类票数要乘以一个权重，最终将各个类别的加权票数求和，最大的值对应的类别为最终类别。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1g0m6tju5udj30ge04u74f.jpg" alt=""></p>
<ol>
<li>学习法</li>
</ol>
<p>上两节的方法都是对弱学习器的结果做平均或者投票，相对比较简单，但是可能学习误差较大，于是就有了学习法这种方法，对于学习法，代表方法是stacking，当使用stacking的结合策略时， 我们不是对弱学习器的结果做简单的逻辑处理，而是再加上一层学习器，也就是说，我们将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。</p>
<p>在这种情况下，我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。</p>
<h2 id="五、-随机森林思想"><a href="#五、-随机森林思想" class="headerlink" title="五、 随机森林思想"></a>五、 随机森林思想</h2><p>随机森林是bagging算法的进化版，改进的部分在于：</p>
<ul>
<li><p>rf使用了cart决策树作为弱学习器</p>
</li>
<li><p>对于普通的决策树，我们会在节点上所有的n个样本特征中选择一个最优的特征来做决策树的左右子树划分，但是RF通过随机选择节点上的一部分样本特征，这个数字小于n，假设为nsub，然后在这些随机选择的nsub个样本特征中，选择一个最优的特征来做决策树的左右子树划分。这样进一步增强了模型的泛化能力。如果nsub=n，则此时RF的CART决策树和普通的CART决策树没有区别。nsub越小，则模型约健壮，当然此时对于训练集的拟合程度会变差。也就是说nsub越小，模型的方差会减小，但是偏倚会增大。在实际案例中，一般会通过交叉验证调参获取一个合适的nsub的值。</p>
</li>
</ul>
<p>过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1. 构建多个数据集</span><br><span class="line"></span><br><span class="line">在包括N个样本的数据集中，采用有放回的抽样方式选择N个样本，构成中间数据集，然后在这个中间数据集的所有特征中随机选择几个特征，作为最终的数据集。以上述方式构建多个数据集；一般回归问题选用全部特征，分类问题选择全部特征个数的平方根个特征</span><br><span class="line"></span><br><span class="line">2. 为每个数据集建立完全分裂的决策树</span><br><span class="line"></span><br><span class="line">利用CART为每个数据集建立一个完全分裂、没有经过剪枝的决策树，最终得到多棵CART决策树；</span><br><span class="line"></span><br><span class="line">3. 预测新数据</span><br><span class="line"></span><br><span class="line">根据得到的每一个决策树的结果来计算新数据的预测值。</span><br><span class="line">- 回归问题：采用多棵树的平均值。</span><br><span class="line">- 分类问题：采用投票计数的方法，票数大的获胜，相同的随机选择。可以把树的棵树设置为奇数避免这一问题。</span><br></pre></td></tr></table></figure></p>
<h2 id="六、-随机森林的推广"><a href="#六、-随机森林的推广" class="headerlink" title="六、 随机森林的推广"></a>六、 随机森林的推广</h2><p>由于RF在实际应用中的良好特性，基于RF，有很多变种算法，应用也很广泛，不光可以用于分类回归，还可以用于特征转换，异常点检测等。下面对于这些RF家族的算法中有代表性的做一个总结。</p>
<h3 id="4-1-extra-trees"><a href="#4-1-extra-trees" class="headerlink" title="4.1 extra trees"></a>4.1 extra trees</h3><p>extra trees是RF的一个变种, 原理几乎和RF一模一样，有区别有：</p>
<ol>
<li><p>对于每个决策树的训练集，RF采用的是随机采样bootstrap来选择采样集作为每个决策树的训练集，而extra trees一般不采用随机采样，即每个决策树采用原始训练集。</p>
</li>
<li><p>在选定了划分特征后，RF的决策树会基于基尼系数，均方差之类的原则，选择一个最优的特征值划分点，这和传统的决策树相同。但是extra trees比较的激进，他会随机的选择一个特征值来划分决策树。</p>
</li>
</ol>
<p>从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于RF所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏倚相对于RF进一步增大。在某些时候，extra trees的泛化能力比RF更好。</p>
<h3 id="4-2-Totally-Random-Trees-Embedding"><a href="#4-2-Totally-Random-Trees-Embedding" class="headerlink" title="4.2 Totally Random Trees Embedding"></a>4.2 Totally Random Trees Embedding</h3><p>Totally Random Trees Embedding(以下简称 TRTE)是一种非监督学习的数据转化方法。它将低维的数据集映射到高维，从而让映射到高维的数据更好的运用于分类回归模型。我们知道，在支持向量机中运用了核方法来将低维的数据集映射到高维，此处TRTE提供了另外一种方法。</p>
<p>TRTE在数据转化的过程也使用了类似于RF的方法，建立T个决策树来拟合数据。当决策树建立完毕以后，数据集里的每个数据在T个决策树中叶子节点的位置也定下来了。比如我们有3颗决策树，每个决策树有5个叶子节点，某个数据特征x划分到第一个决策树的第2个叶子节点，第二个决策树的第3个叶子节点，第三个决策树的第5个叶子节点。则x映射后的特征编码为(0,1,0,0,0,     0,0,1,0,0,     0,0,0,0,1), 有15维的高维特征。这里特征维度之间加上空格是为了强调三颗决策树各自的子编码。</p>
<p>映射到高维特征后，可以继续使用监督学习的各种分类回归算法了。</p>
<h3 id="4-3-Isolation-Forest"><a href="#4-3-Isolation-Forest" class="headerlink" title="4.3 Isolation Forest"></a>4.3 Isolation Forest</h3><p>Isolation Forest（以下简称IForest）是一种异常点检测的方法。它也使用了类似于RF的方法来检测异常点。</p>
<p>对于在T个决策树的样本集，IForest也会对训练集进行随机采样,但是采样个数不需要和RF一样，对于RF，需要采样到采样集样本个数等于训练集个数。但是IForest不需要采样这么多，一般来说，采样个数要远远小于训练集个数？为什么呢？因为我们的目的是异常点检测，只需要部分的样本我们一般就可以将异常点区别出来了。</p>
<p>对于每一个决策树的建立， IForest采用随机选择一个划分特征，对划分特征随机选择一个划分阈值。这点也和RF不同。</p>
<p>另外，IForest一般会选择一个比较小的最大决策树深度max_depth,原因同样本采集，用少量的异常点检测一般不需要这么大规模的决策树。</p>
<p>对于异常点的判断，则是将测试样本点x拟合到T颗决策树。计算在每颗决策树上该样本的叶子节点的深度ht(x),从而可以计算出平均高度h(x)。此时我们用下面的公式计算样本点x的异常概率:</p>
<p>s(x,m)=2−h(x)c(m)</p>
<p>其中，m为样本个数。</p>
<p>c(m)的表达式为：</p>
<p>c(m)=2ln(m−1)+ξ−2m−1m,ξ为欧拉常数</p>
<p>s(x,m)的取值范围是[0,1],取值越接近于1，则是异常点的概率也越大。</p>
<h2 id="七、-优缺点"><a href="#七、-优缺点" class="headerlink" title="七、 优缺点"></a>七、 优缺点</h2><ol>
<li>RF的主要优点有：</li>
</ol>
<ul>
<li><p>训练可以高度并行化，对于大数据时代的大样本训练速度有优势。个人觉得这是的最主要的优点。</p>
</li>
<li><p>由于可以随机选择决策树节点划分特征，这样在样本特征维度很高的时候，仍然能高效的训练模型。</p>
</li>
<li><p>在训练后，可以给出各个特征对于输出的重要性</p>
</li>
<li><p>由于采用了随机采样，训练出的模型的方差小，泛化能力强。</p>
</li>
<li><p>相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。</p>
</li>
<li><p>对部分特征缺失不敏感。</p>
</li>
</ul>
<ol start="2">
<li>RF的主要缺点有：</li>
</ol>
<ul>
<li><p>在某些噪音比较大的样本集上，RF模型容易陷入过拟合。</p>
</li>
<li><p>取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果。</p>
</li>
</ul>
<h2 id="八、-sklearn参数2"><a href="#八、-sklearn参数2" class="headerlink" title="八、 sklearn参数2"></a>八、 sklearn参数2</h2><p>下面我们再来看RF的决策树参数，它要调参的参数基本和GBDT相同，如下:</p>
<p>　　　　1) RF划分时考虑的最大特征数max_features: 可以使用很多种类型的值，默认是”auto”,意味着划分时最多考虑N−−√N个特征；如果是”log2”意味着划分时最多考虑log2N个特征；如果是”sqrt”或者”auto”意味着划分时最多考虑N−−√N个特征。如果是整数，代表考虑的特征绝对数。如果是浮点数，代表考虑特征百分比，即考虑（百分比xN）取整后的特征数。其中N为样本总特征数。一般我们用默认的”auto”就可以了，如果特征数非常多，我们可以灵活使用刚才描述的其他取值来控制划分时考虑的最大特征数，以控制决策树的生成时间。</p>
<p>　　　　1) 决策树最大深度max_depth: 默认可以不输入，如果不输入的话，决策树在建立子树的时候不会限制子树的深度。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。</p>
<p>　　　　2) 内部节点再划分所需最小样本数min_samples_split: 这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</p>
<p>　　　　3) 叶子节点最少样本数min_samples_leaf: 这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1,可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</p>
<p>　　　　5）叶子节点最小的样本权重和min_weight_fraction_leaf：这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。 默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。</p>
<p>　　　　6) 最大叶子节点数max_leaf_nodes: 通过限制最大叶子节点数，可以防止过拟合，默认是”None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制，具体的值可以通过交叉验证得到。</p>
<p>　　　　7) 节点划分最小不纯度min_impurity_split:  这个值限制了决策树的增长，如果某节点的不纯度(基于基尼系数，均方差)小于这个阈值，则该节点不再生成子节点。即为叶子节点 。一般不推荐改动默认值1e-7。</p>
<p>　　　　上面决策树参数中最重要的包括最大特征数max_features， 最大深度max_depth， 内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf。</p>
<h2 id="九、应用场景"><a href="#九、应用场景" class="headerlink" title="九、应用场景"></a>九、应用场景</h2><p>数据维度相对低（几十维），同时对准确性有较高要求时。</p>
<p>因为不需要很多参数调整就可以达到不错的效果，基本上不知道用什么方法的时候都可以先试一下随机森林。</p>
<p>参考资料：</p>
<p><a href="http://www.cnblogs.com/pinard/p/6131423.html" target="_blank" rel="noopener">http://www.cnblogs.com/pinard/p/6131423.html</a></p>
<p><a href="https://blog.csdn.net/qq_36330643/article/details/77621232" target="_blank" rel="noopener">https://blog.csdn.net/qq_36330643/article/details/77621232</a></p>
<p><a href="http://chrer.com/2018/07/24/集成学习常见模型/" target="_blank" rel="noopener">http://chrer.com/2018/07/24/集成学习常见模型/</a></p>
<p><a href="http://www.tensorinfinity.com/upload/files/20190121/1548062905762703.pdf" target="_blank" rel="noopener">http://www.tensorinfinity.com/upload/files/20190121/1548062905762703.pdf</a></p>

          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/26/贝叶斯/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/26/贝叶斯/" itemprop="url">贝叶斯</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-26T21:03:59+08:00">
                2019-02-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  0
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/26/k-means/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/26/k-means/" itemprop="url">k-means</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-26T09:42:23+08:00">
                2019-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/数据挖掘-算法/" itemprop="url" rel="index">
                    <span itemprop="name">数据挖掘 算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  256
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一、相异度计算"><a href="#一、相异度计算" class="headerlink" title="一、相异度计算"></a>一、相异度计算</h2><blockquote>
<p>相异度即两个东西差别有多大。</p>
</blockquote>
<p>人的直观感受下，人与羊的相异度明显大于人与猩猩的相异度。但是如何把这种感受传递给计算机，我们必须对使用数学语言描述出相异度。</p>
<h3 id="1-标量下的相异度计算"><a href="#1-标量下的相异度计算" class="headerlink" title="1.标量下的相异度计算"></a>1.标量下的相异度计算</h3><blockquote>
<p>标量即无方向意义的数字。</p>
</blockquote>
<p>设x=(1,2,3),y=(4,5,6)</p>
<ul>
<li><p>欧式距离</p>
</li>
<li><p>曼哈顿距离</p>
</li>
<li><p>闵可夫斯基距离</p>
</li>
<li><p>皮尔逊系数(Pearson Correlation Coefficient)</p>
</li>
</ul>
<p>归一化问题</p>
<p>以上计算存在一个问题：取值范围大的属性对距离的影响高于取值范围小的属性。为了解决这个问题，一般要进行归一化。</p>
<p>归一化就是将各个属性值按比例映射到相同的取值区间，这样是为了平衡各个属性对距离的影响。通常将各个属性均映射到[0,1]区间，映射公式为：</p>
<p><a href="https://www.kancloud.cn/wizardforcel/dm-algo-top10/116021" target="_blank" rel="noopener">https://www.kancloud.cn/wizardforcel/dm-algo-top10/116021</a></p>

          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/19/正则表达式/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/19/正则表达式/" itemprop="url">正则表达式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-19T11:51:55+08:00">
                2019-02-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  27
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>nlp 正则表达式 </p>
<p>把日期去掉</p>
<p>匹配实体<br>[.<em>?][a-z]+?</em><br>[.<em>?][a-z]+?$</em>|</p>
<p><a href="https://blog.csdn.net/weixin_41929524/article/details/79980164" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41929524/article/details/79980164</a></p>

          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/30/动态规划/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="thinks">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="thinks's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/30/动态规划/" itemprop="url">动态规划</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-30T13:46:02+08:00">
                2019-01-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  0
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    
    
    <div>
  
</div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">thinks</p>
              <p class="site-description motion-element" itemprop="description">start from zero</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">31</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">thinks</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">16.1k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
